{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abrham17/Diffusion_model-UNet-implementation/blob/main/Diffusion_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lbtY1yddOONI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, utils as vutils\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NoWAgqmp2GK0"
      },
      "outputs": [],
      "source": [
        "# Noise schedule\n",
        "def get_noise_schedule(T=1000, beta_start=0.0001, beta_end=0.02):\n",
        "    betas = torch.linspace(beta_start, beta_end, T)\n",
        "    alphas = 1.0 - betas\n",
        "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "    return betas, alphas, alphas_cumprod\n",
        "\n",
        "# Forward diffusion\n",
        "def forward_diffusion(x_0, t, alphas_cumprod, device):\n",
        "    noise = torch.randn_like(x_0).to(device)\n",
        "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod[t]).view(-1, 1, 1, 1)\n",
        "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod[t]).view(-1, 1, 1, 1)\n",
        "    x_t = sqrt_alphas_cumprod * x_0 + sqrt_one_minus_alphas_cumprod * noise\n",
        "    return x_t, noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1W3wFpOr2QDj"
      },
      "outputs": [],
      "source": [
        "# Sinusoidal embedding\n",
        "def get_sinusoidal_embedding(t, time_dim, device):\n",
        "    half_dim = time_dim // 2\n",
        "    emb = torch.log(torch.tensor(10000.0)) / (half_dim - 1)\n",
        "    emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "    # Corrected line: Multiply t (batch_size, 1) with emb expanded to (1, half_dim)\n",
        "    emb = t * emb[None, :]\n",
        "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
        "    return emb\n",
        "\n",
        "# Visualization\n",
        "def visualize_samples(samples, step, epoch):\n",
        "    samples = (samples.clamp(-1, 1) + 1) / 2\n",
        "    grid = vutils.make_grid(samples, nrow=8, normalize=True)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
        "    plt.title(f\"Epoch {epoch}, Step {step}\")\n",
        "    plt.axis('off')\n",
        "    plt.savefig(f\"epoch_{epoch}_step_{step}.png\")\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JtMBmpPC2k4y"
      },
      "outputs": [],
      "source": [
        "# Sampling\n",
        "def sample(model, n_samples, in_channels, height, width, num_classes, T, betas, alphas, alphas_cumprod, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        x = torch.randn(n_samples, in_channels, height, width).to(device)\n",
        "        c = torch.randint(0, num_classes, (n_samples,)).to(device)\n",
        "        for t in reversed(range(T)):\n",
        "            t_tensor = torch.full((n_samples,), t, dtype=torch.float, device=device)\n",
        "            predicted_noise = model(x, t_tensor, c)\n",
        "            alpha_t = alphas[t].view(-1, 1, 1, 1)\n",
        "            beta_t = betas[t].view(-1, 1, 1, 1)\n",
        "            alpha_cumprod_t = alphas_cumprod[t].view(-1, 1, 1, 1)\n",
        "            x = (1 / torch.sqrt(alpha_t)) * (x - (beta_t / torch.sqrt(1 - alpha_cumprod_t)) * predicted_noise)\n",
        "            if t > 0:\n",
        "                x += torch.sqrt(beta_t) * torch.randn_like(x)\n",
        "        return x, c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MCvm5-2Q9iH5"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "      \"\"\"\n",
        "      UNet architecture for conditional Denoising Diffusion Probabilistic Models (DDPMs).\n",
        "      args:\n",
        "          in_channels (int): Number of input channels.\n",
        "          out_channels (int): Number of output channels.\n",
        "          time_dim (int): Dimension of the time embedding.\n",
        "          num_classes (int): Number of conditional generation.\n",
        "      returns:\n",
        "          out (Tensor): Predicted noise tensor for the reverse diffusion process.\n",
        "      process:\n",
        "          1. Down sampling: from in_channels to 64, 128, 256.\n",
        "          2. Bottleneck: from 256 to 256.\n",
        "          3. Up sampling: from 256 to 128, 64, out_channels.\n",
        "      \"\"\"\n",
        "      def __init__(self, in_channels=1, out_channels=1, time_dim=128, num_classes=None):\n",
        "          super(UNet, self).__init__()\n",
        "          self.down1 = nn.Sequential(\n",
        "              nn.Conv2d(in_channels, 64, 3, padding=1),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU()\n",
        "          )\n",
        "          self.down2 = nn.Sequential(\n",
        "              nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "              nn.BatchNorm2d(128),\n",
        "              nn.ReLU()\n",
        "          )\n",
        "          self.bottleneck = nn.Sequential(\n",
        "              nn.Conv2d(128, 256, 3, padding=1),\n",
        "              nn.BatchNorm2d(256),\n",
        "              nn.ReLU()\n",
        "          )\n",
        "          self.up1 = nn.Sequential(\n",
        "              nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
        "              nn.BatchNorm2d(128),\n",
        "              nn.ReLU()\n",
        "          )\n",
        "          self.up2 = nn.Sequential(\n",
        "              nn.Conv2d(128 + 64, 64, 3, padding=1),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU()\n",
        "          )\n",
        "          self.out = nn.Conv2d(64, out_channels, 3, padding=1)\n",
        "          self.time_dim = time_dim\n",
        "          self.class_emb = nn.Embedding(num_classes, time_dim) if num_classes else None\n",
        "          self.emb_projection = nn.Conv2d(time_dim, 64, 1)\n",
        "\n",
        "      def forward(self, x, t, c=None):\n",
        "          t_emb = get_sinusoidal_embedding(t, self.time_dim, x.device)\n",
        "          c_emb = self.class_emb(c) if c is not None else torch.zeros_like(t_emb)\n",
        "          emb = t_emb + c_emb\n",
        "          emb = emb.view(-1, self.time_dim, 1, 1)\n",
        "          emb = self.emb_projection(emb)\n",
        "          d1 = self.down1(x) + emb\n",
        "          d2 = self.down2(d1)\n",
        "          b = self.bottleneck(d2)\n",
        "          u1 = self.up1(b)\n",
        "          u2 = self.up2(torch.cat([u1, d1], dim=1))\n",
        "          out = self.out(u2)\n",
        "          return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULsHyKZOZ3mN",
        "outputId": "876ae1e4-78b0-42a8-bc58-d6ed9e47c22a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 40.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.11MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 8.79MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.06060605171495981\n",
            "Epoch: 2, Loss: 0.054923035764395556\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "all_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "train_data = MNIST(root='./data', train=True, download=True, transform=all_transforms)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "model = UNet(in_channels=1, out_channels=1, time_dim=128, num_classes=10).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "T = 1000\n",
        "betas, alphas, alphas_cumprod = get_noise_schedule(T)\n",
        "betas, alphas, alphas_cumprod = betas.to(device), alphas.to(device), alphas_cumprod.to(device)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        t = torch.randint(0, T, (x.shape[0],), device=device).float()\n",
        "        # Reshape t to (batch_size, 1)\n",
        "        t = t.view(-1, 1)\n",
        "        x_t, noise = forward_diffusion(x, t.long(), alphas_cumprod, device)\n",
        "        predicted_noise = model(x_t, t, y)\n",
        "        loss = criterion(predicted_noise, noise)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "    # Visualize samples every epoch\n",
        "    samples, classes = sample(model, 64, 1, 28, 28, 10, T, betas, alphas, alphas_cumprod, device)\n",
        "    visualize_samples(samples, 0, epoch+1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyM6ksRNb+eAPMY9MP7Ia+yy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}