{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMuH9Z3/3sPZQm+NP0DHMl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abrham17/Diffusion_model-UNet-implementation/blob/main/Diffusion_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCvm5-2Q9iH5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    UNet architecture for conditional Denoising Diffusion Probabilistic Models (DDPMs).\n",
        "    args:\n",
        "        in_channels (int): Number of input channels.\n",
        "        out_channels (int): Number of output channels.\n",
        "        time_dim (int): Dimension of the time embedding.\n",
        "        num_classes (int): Number of conditional generation.\n",
        "    returns:\n",
        "        out (Tensor): Predicted noise tensor for the reverse diffusion process.\n",
        "    process:\n",
        "        1. Down sampling: from in_channels to 64, 128, 256.\n",
        "        2. Bottleneck: from 256 to 256.\n",
        "        3. Up sampling: from 256 to 128, 64, out_channels.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=1, out_channels=1, time_dim=128, num_classes=None):\n",
        "        super(UNet, self).__init__()\n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.bottleneck = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.Conv2d(128 + 64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.out = nn.Conv2d(64, out_channels, 3, padding=1)\n",
        "        self.time_emb = nn.Linear(1, time_dim)\n",
        "        self.class_emb = nn.Embedding(num_classes, time_dim) if num_classes else None\n",
        "\n",
        "    def forward(self, x, t, c=None):\n",
        "        t_emb = self.time_emb(t)\n",
        "        c_emb = self.class_emb(c) if c is not None else 0\n",
        "        d1 = self.down1(x)\n",
        "        d2 = self.down2(d1)\n",
        "        b = self.bottleneck(d2)\n",
        "        u1 = self.up1(b)\n",
        "        u2 = self.up2(torch.cat([u1, d1], dim=1))\n",
        "        out = self.out(u2)\n",
        "        return out"
      ]
    }
  ]
}